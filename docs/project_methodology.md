Universal Methodology for Setting Up Your Project
1. Start with Clear, Written Requirements
Before writing any code or prompting your AI assistant, create a detailed Product Requirements Document (PRD). In this document, include:

Project Overview: Summarize what you’re building and its primary purpose.
Core Functionalities: List essential features and requirements. Consider what the app must do at a minimum to be useful.
Technology Stack: Decide on frameworks, libraries, and tools for frontend, backend, database, and integrations with AI APIs.
Data Flow and Structure: Understand where your data comes from, how it’s processed, and where it will be stored.
Dependencies and Documentation: Identify libraries, packages, or third-party services you plan to use, and gather code examples or official docs for reference.
The more detailed and specific this PRD is, the better aligned your AI assistant (and future contributors) will be when writing code.

2. Conduct Preliminary Research and Proof of Concepts
Don’t rely solely on your AI assistant to guess what you need. Do some initial exploration:

Research Libraries and APIs: Identify the best tools for your data fetching, model integrations, or UI components. Check official documentation and examples.
Test Key Integrations: Write a minimal script that tests a crucial part of your functionality (e.g., making an API call, sending a prompt to an LLM, or querying a database).
Validate Credentials and Configurations: Ensure environment variables, API keys, and tokens are correct and that your initial test calls succeed.
By having a working proof of concept, you reduce guesswork and prevent your AI assistant from producing code that repeatedly fails due to unclear requirements.

3. Create a Well-Organized File Structure Early
Define a logical file and folder structure to keep your project maintainable. For example:
app/ or src/: Contains your frontend pages, components, or routes.
lib/ or services/: Contains backend service integrations, utility functions, or API wrappers.
db/ or database/: Holds database client configurations and schema-related code.
instructions/: Stores your documentation (PRD, setup guides, feature specs) for quick reference.
.env: Used for environment variables like API keys and credentials.
A predefined, clean structure reduces ambiguity for your AI assistant and team members.

4. Leverage Reasoning-Heavy LLMs for Documentation Refinement
Use a more capable, reasoning-focused LLM (like GPT-4 or Claude) to review and refine your PRD and architecture plan before coding. Ask it to:

Suggest improvements to your file structure.
Propose a more minimal, coherent approach to reduce complexity.
Fill in missing details in your requirements.
This step helps clarify your vision and reduces friction once you start implementing features with your AI code editor.

5. Prepare Code Examples and References
Curate small, self-contained code snippets demonstrating how to:

Call external APIs or fetch data.
Use the LLM API with structured output.
Interact with the database or storage layer.
Having these examples ready allows you to provide direct references to your AI assistant, improving the quality of generated code and reducing trial-and-error.

6. Incremental Prompting and Development
When using your AI code assistant, avoid asking it to build the entire application at once. Instead:

Break your implementation into small, manageable tasks.
For each task, provide the relevant portion of your PRD, highlight the dependencies, and paste in the code examples you prepared.
After each step is implemented, test and verify before moving on.
This incremental approach leads to better results, as the AI can handle complexity more effectively when dealing with smaller, well-defined subtasks.

7. Integrate Observability and Monitoring Early
If your application relies on LLM calls, consider setting up logging, monitoring, and debugging tools right from the start. For example, use a platform that can:

Track request payloads, responses, and costs for each LLM call.
Provide error logs and performance metrics so you can quickly diagnose issues.
Enable caching or other optimizations to control runtime costs and latency.
Having observability in place helps you iterate on prompts, optimize performance, and control expenses from day one.

8. Refine, Iterate, and Enhance
Once the core functionality works:

Enhance the user interface and user experience, possibly using AI design tools to improve layout and style.
Optimize data flows and reduce unnecessary computations or API calls.
Add security measures, handle edge cases, and polish documentation.
Continuously revisit your PRD to ensure the product aligns with original goals and to track what features remain to be implemented.
Use the feedback loop: logs and metrics from production, user feedback, and results from monitoring tools can inform ongoing refinements.
